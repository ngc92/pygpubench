"""
EXPLOIT #2: GC Answer Copy
============================
Severity: CRITICAL

Strategy:
  At import time, use gc to find both kernel arg tuples (output0, output1, input) and
  expected result tuples (expected_tensor, rtol, atol). Build a mapping from
  output tensor data_ptr -> expected tensor. In the kernel, just copy the
  expected answer to the output.

  Matching heuristic: gc.get_objects() approximately preserves allocation order.
  kernel_arg[i] and expected[i] were created at the same index in setup_benchmark.

Attack surface: Python gc introspection + shared CUDA address space.
"""
import gc
import sys

print("[GC Copy] Scanning gc.get_objects() for kernel args and expected outputs...", file=sys.stderr)

_answer_map = {}  # output_data_ptr -> expected_tensor

try:
    import torch

    kernel_arg_tuples = []
    expected_tuples = []

    for obj in gc.get_objects():
        if isinstance(obj, tuple) and len(obj) == 3:
            try:
                a, b, c = obj
                if (isinstance(a, torch.Tensor) and a.is_cuda
                        and isinstance(b, torch.Tensor) and b.is_cuda
                        and isinstance(c, torch.Tensor) and c.is_cuda
                        and a.ndim == 2 and b.ndim == 2 and c.ndim == 3):
                    kernel_arg_tuples.append(obj)
            except Exception:
                pass
            try:
                a, b, c = obj
                if (isinstance(a, torch.Tensor) and a.is_cuda
                        and isinstance(b, float) and isinstance(c, float)
                        and 0 < b < 1 and 0 < c < 1):
                    expected_tuples.append(obj)
            except Exception:
                pass

    print(f"[GC Copy] Found {len(kernel_arg_tuples)} kernel arg tuples, {len(expected_tuples)} expected tuples", file=sys.stderr)

    # Match by allocation order (heuristic) and flatten both outputs.
    output_tensors = []
    for output0, output1, _ in kernel_arg_tuples:
        output_tensors.append(output0)
        output_tensors.append(output1)
    for i in range(min(len(output_tensors), len(expected_tuples))):
        _answer_map[output_tensors[i].data_ptr()] = expected_tuples[i][0]

    print(f"[GC Copy] Built answer map with {len(_answer_map)} entries", file=sys.stderr)

except Exception as e:
    print(f"[GC Copy] Setup failed: {e}", file=sys.stderr)


def kernel(output_gray, output_red, inp):
    """Copy expected answers directly to output tensors."""
    expected_gray = _answer_map.get(output_gray.data_ptr())
    expected_red = _answer_map.get(output_red.data_ptr())
    if expected_gray is not None:
        output_gray.copy_(expected_gray)
    else:
        import torch
        weights = torch.tensor([0.2989, 0.5870, 0.1140], device=output_gray.device, dtype=output_gray.dtype)
        torch.sum(inp * weights, dim=-1, out=output_gray)
    if expected_red is not None:
        output_red.copy_(expected_red)
    else:
        output_red.copy_(inp[..., 0])
